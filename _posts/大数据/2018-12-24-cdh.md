---
layout: post
category: 大数据
---

>CDH


# 1 概述

参考文档：
https://www.cloudera.com/documentation/enterprise/6/release-notes/topics/rg_cdh_60_download.html

rpm下载地址：
parcels： https://archive.cloudera.com/cdh6/6.0.0/parcels/
cm： https://archive.cloudera.com/cdh6/6.0.0/redhat7/yum/

# 2 安装
## 2.1 离线安装
### 2.1.1  cm parcels 离线安装
cm server & cm agent 已写好ansible-playbooks安装【所以这里跳过，后续介绍】

- parcels配置

![-w1251](/assets/img//15459698443545.jpg)

- parcels下载与激活

>以SPARK2为例，其他parcel激活方法相同

![-w272](/assets/img//15459698995701.jpg)


![-w1427](/assets/img//15459699461752.jpg)

![-w1114](/assets/img//15459699642753.jpg)

![-w1135](/assets/img//15459699809123.jpg)

### 2.1.2 SPARK2 Install
```
#csd文件下载地址 https://www.cloudera.com/documentation/spark2/latest/topics/spark2_packaging.html

将在的问题件复制到此目录
/opt/cloudera/csd/SPARK2_ON_YARN-2.3.0.cloudera3.jar
从起cm服务，然后通过parcels进行安装
```
- 添加服务

![-w431](/assets/img//15459692481049.jpg)

- 就可以看到SPARK2，安装过程点点点，就不详细截图了
 
![-w1273](/assets/img//15459692630744.jpg)

- 安装后

![](/assets/img//15459693848310.jpg)

- 环境变量-配置文件目录 更新


```
#configure_spark2_as_default.sh 所有节点执行
#! /bin/bash
for binary in pyspark spark-shell spark-submit; do
  # Generate the name of the new binary e.g. pyspark2, spark2-shell, etc.
  new_binary=$(echo $binary | sed -e 's/spark/spark2/')
  # Update the old alternative to the client binary to the new client binary
  # Use priority 11 because the default priority with which these alternatives are created is 10
  update-alternatives --install /usr/bin/${binary} ${binary} /usr/bin/${new_binary} 11
done
# For configuration, we need to have a separate command
# because the destination is under /etc/ instead of /usr/bin like for binaries.
# The priority is different - 52 because Cloudera Manager sets up configuration symlinks
# with priority 51.
update-alternatives --install /etc/spark/conf spark-conf /etc/spark2/conf 52
```
### 2.1.3 Kerberos
> 先搭建Kerberos服务，一键ansible-playbook已写好，kerberos安装以及主备数据同步后续写单独写一篇文章，本章只描述CDH如何对接Kerberos
Kerberos-Install-URL=http://wangbokun.com/xxxx



### 2.1.4 S3 connector

### 2.1.5 Sentry

## 2.2 CM UI操作
### 2.2.1 体验cm 6.0 UI
全新UI
![](/assets/img/15367225129596.jpg)

![](/assets/img/15367225297704.jpg)
![](/assets/img/15367225806551.jpg)

![](/assets/img/15367226502420.jpg)
![](/assets/img/15367228742719.jpg)
![](/assets/img/15367230163740.jpg)
![](/assets/img/15367230301893.jpg)
![](/assets/img/15367231791974.jpg)
![](/assets/img/15367232230193.jpg)
![](/assets/img/15367233231281.jpg)
![](/assets/img/15367243350295.jpg)
![](/assets/img/15367243727237.jpg)
![](/assets/img/15367257840304.jpg)
![](/assets/img/15367258083804.jpg)

### 2.2.2 NN HA
点击开启HA，选择角色，NN&&JN，然后配置元数据目录，继续后出现一下界面
![](/assets/img/15367272865251.jpg)

    
/data/cloudera/parcel-repo
http://xxx/cdh/cdh6/parcels/

# 3 配置
## 3.1 cm conntion s3 configure
- 安装s3 connector服务，安装过程不详写，图形界面点点点

![](/assets/img//15456397421030.jpg)

- 配置s3 endpoint，例如北京区(s3.cn-north-1.amazonaws.com.cn)

![](/assets/img//15456398480249.jpg)

- hdfs 配置s3 key

![](/assets/img//15456399268442.jpg)

# 3.2 Yarn
## 3.2.1 YARN 内存CPU配置公式
>  http://tiny.cloudera.com/yarn-tuning-guide

* RAM-per-container is minimum-allocation-mb ，一般设置为1024m.

Configuration File | Configuration Setting | Value Calculation
:----------- | :-----------: | -----------:
yarn-site.xml         | yarn.nodemanager.resource.memory-mb        | containers * RAM-per-container
yarn-site.xml         | yarn.scheduler.minimum-allocation-mb        | RAM-per-container
yarn-site.xml         | yarn.scheduler.maximum-allocation-mb        | containers * RAM-per-container
yarn-site.xml         | yarn.app.mapreduce.am.resource.mb        | 2 * RAM-per-container
yarn-site.xml         | yarn.app.mapreduce.am.command-opts        | 0.8 * 2 * RAM-per-container
mapred-site.xml       | mapreduce.map.memory.mb        | RAM-per-container
mapred-site.xml       | mapreduce.reduce.memory.mb        | 2 * RAM-per-container
mapred-site.xml       | mapreduce.map.java.opts        | 0.8 * RAM-per-container
mapred-site.xml       | mapreduce.reduce.java.opts        | 0.8 * 2 * RAM-per-container
## 3.2.2 Yarn scheduler queue


![-w846](/assets/img/15469350195055.jpg)
![](/assets/img//15469353611646.jpg)

![-w580](/assets/img//15469349264854.jpg)

- 设置root访问控制

![-w1397](/assets/img//15469356489937.jpg)
![-w837](/assets/img//15469356653564.jpg)

![-w871](/assets/img//15469356805546.jpg)

- 设置 root.default

![-w1420](/assets/img//15469351509733.jpg)

![-w886](/assets/img//15469351835867.jpg)

![-w874](/assets/img//15469352306909.jpg)

- 设置不限制用户

![-w883](/assets/img//15469357617819.jpg)

![-w874](/assets/img//15469357734427.jpg)

- 设置提交job用户白名单

![-w856](/assets/img//15469358916303.jpg)

- 设置管理queue的用户白名单【多个用户用逗号分隔】

![-w859](/assets/img//15469359155499.jpg)

![-w1408](/assets/img//15469360595297.jpg)
- 删除允许自动创建用户queue
![-w1419](/assets/img//15469361451964.jpg)

- 打开Yarn scheduler 显示以下界面
![-w1225](/assets/img//15469363220449.jpg)


# 3.3 HDFS
## 3.3.1 hdfs-web-http

| 配置 | value | 说明  |
| --- | --- | --- |
| hdfs.httpfs.http.port | 14000 |端口  |
|dfs.webhdfs.enabled|true|开启httpfs|

```
cloudera manager->hdfs->实例-> 添加角色-> HttpFS角色选择主机


简单测试：
curl -i  "http://127.0.0.1:14000/webhdfs/v1/user/root/?op=LISTSTATUS&user.name=root"
```
## 3.3.1 hdfs mount
> 参考文档:https://www.cloudera.com/documentation/enterprise/5-9-x/topics/cdh_ig_hdfs_mountable.html

```
#如果是通过cloudera manager 安装的集群不需要手动安装hadoop-hdfs-fuse
直接mount就可以了
DIR=/cdh && mkdir -p  $DIR
hadoop-fuse-dfs hdfs://cdh:8020 $DIR
#如果集群接入了kerberos，需要用户kinit之后才可以看到本地hdfs目录，反之本地hdfs看不到
```

# 4 Kerberos以及用户管理
playbooks已实现自动安装，以及主备同步.
## 4.1 cm开始kerberos认证
![-w449](/assets/img//15464856090372.jpg)

![-w1214](/assets/img//15464856363455.jpg)

![-w1222](/assets/img//15464857776289.jpg)

![-w1242](/assets/img//15464858638161.jpg)

![-w1289](/assets/img//15464858974929.jpg)


![-w1249](/assets/img//15464859921796.jpg)

![-w512](/assets/img//15464860107793.jpg)

![-w1261](/assets/img//15464860224266.jpg)

![-w1245](/assets/img//15464860566979.jpg)

![-w1271](/assets/img//15464860826080.jpg)

![-w1269](/assets/img//15464860990119.jpg)

![-w407](/assets/img//15464875859499.jpg)

![-w966](/assets/img//15464876056430.jpg)

![-w1191](/assets/img//15464876539669.jpg)

## 4.2 Sentry服务

> 命令参考 
> https://www.cloudera.com/documentation/enterprise/5-8-x/topics/impala_show.html
> https://www.cnblogs.com/bugsbunny/p/7097958.html

![-w1284](/assets/img//15464877588807.jpg)

![-w1316](/assets/img//15464878286307.jpg)

![-w1329](/assets/img//15464879467695.jpg)

![-w1246](/assets/img//15464880124775.jpg)

![-w1282](/assets/img//15464880303113.jpg)


![-w417](/assets/img//15464880561600.jpg)

## 4.3 权限配置
### 4.3.1 hive  sentry
![-w1404](/assets/img//15469302171719.jpg)

![-w791](/assets/img//15469375670441.jpg)

![](/assets/img//15469377845069.jpg)

![-w626](/assets/img//15469378555294.jpg)

![-w605](/assets/img//15469378909395.jpg)

- sentry group user
![-w1087](/assets/img//15469310181327.jpg)

![-w1097](/assets/img//15469310292703.jpg)
### 4.3.2 HDFS sentry

```
<property>
    <name>fs.s3a.access.key</name>
    <value></value>
</property>

<property>
    <name>fs.s3a.secret.key</name>
    <value></value>
</property>

<property>
    <name>hadoop.proxyuser.root.groups</name>
    <value>*</value>
</property>

<property>
    <name>hadoop.proxyuser.root.hosts</name>
    <value>*</value>
</property>

<property>
    <name>hadoop.proxyuser.livy.groups</name>
    <value>*</value>
</property>

<property>
    <name>hadoop.proxyuser.livy.hosts</name>
    <value>*</value>
</property>

<property>
    <name>fs.s3a.fast.upload</name>
    <value>true</value>
</property>

<property>
    <name>fs.s3a.fast.upload.buffer</name>
    <value>disk</value>
</property>

<property>
    <name>hadoop.proxyuser.zeppelin.groups</name>
    <value>*</value>
</property>

<property>
    <name>hadoop.proxyuser.zeppelin.hosts</name>
    <value>*</value>
</property>

<property>
    <name>hadoop.proxyuser.presto.groups</name>
    <value>*</value>
</property>
    
<property>
    <name>hadoop.proxyuser.presto.hosts</name>
    <value>*</value>
</property>
```
![-w1367](/assets/img//15469374198120.jpg)

![-w440](/assets/img//15469377225233.jpg)
### 4.3.3 Hue sentry


```
预先添加hive_admin 组的权限，用命令行添加权限
hive的机器上寻找keytab，先找到pid最大的目录
$ ll /var/run/cloudera-scm-agent/process |grep hive-HIVESERVER2
$ cd /var/run/cloudera-scm-agent/process/482-hive-HIVESERVER2
$ ls -al hive.keytab
-rw-------. 1 hive hive  1570 1月   8 17:01 hive.keytab
$ kinit -kt hive.keytab hive/xxx@xxx.COM

# 用beeline链接hive
beeline
!connect jdbc:hive2://localhost:10000/;principal=hive/xxx.COM;
create role hive_admin_role;
grant all on server server1 to role hive_admin_role;
grant role hive_admin_role to group hive_admin;
```

![](/assets/img//15469395486417.jpg)

![-w778](/assets/img//15469346615420.jpg)

- 重启服务后，HUE出现Security菜单
![-w204](/assets/img//15469367135545.jpg)

![-w1142](/assets/img//15469386514019.jpg)

![-w787](/assets/img//15469387221329.jpg)

![-w1124](/assets/img//15469412391614.jpg)



# 5 Cloudera Manager  S3 
![-w459](/assets/img//15464881365130.jpg)


![-w1281](/assets/img//15464881642340.jpg)

![-w1239](/assets/img//15464881840169.jpg)

![-w611](/assets/img//15464882167052.jpg)

![-w903](/assets/img//15464882377187.jpg)
![-w888](/assets/img//15464902431955.jpg)
![-w1295](/assets/img//15464902722481.jpg)
![-w1240](/assets/img//15464902829423.jpg)

![-w1278](/assets/img//15464902998833.jpg)

![-w1256](/assets/img//15464904136786.jpg)

![-w1276](/assets/img//15464904312191.jpg)

![-w1419](/assets/img//15464904485704.jpg)


![-w1431](/assets/img//15464905503870.jpg)

```
region name:
s3.cn-north-1.amazonaws.com.cn
之后提示同步配置，并重启服务.
```
![-w405](/assets/img//15464906132029.jpg)

# 6 Hue 
## 6.1 Hue LDAP
![-w613](/assets/img//15469409673292.jpg)

![](/assets/img//15469344933212.jpg)

![](/assets/img//15469345683527.jpg)

## 6.2 手动导入用户
![-w1110](/assets/img//15469368094366.jpg)
 
 ![-w541](/assets/img//15469368274187.jpg)

![-w129](/assets/img//15469368413706.jpg)
- admin group
![](/assets/img//15469384618009.jpg)

![-w608](/assets/img//15469385068925.jpg)

![-w545](/assets/img//15469370429066.jpg)
![-w603](/assets/img//15469385438968.jpg)

![-w606](/assets/img//15469385688453.jpg)

![-w600](/assets/img//15469385946608.jpg)
# 7 HDFS
## 7.1 hadoop fs
### 7.1.1 appendToFile
```
[~]$ echo a > a
[~]$ echo b > b
[~]$ hadoop fs -appendToFile b appendToFile/a 
[~]$ hadoop fs -cat  appendToFile/a
a
b
```
### 7.1.2 checksum
```
[~]$ hadoop fs -checksum  appendToFile/a
appendToFile/a	MD5-of-0MD5-of-512CRC32C	000002000000000000000000b0a41fe649f3230d9e76f743d1345b2a
```
### 7.1.3 chgrp chmod chown
  [-chgrp [-R] GROUP PATH...]
	[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
	[-chown [-R] [OWNER][:[GROUP]] PATH...]
	[-copyFromLocal [-f] [-p] [-l] <localsrc> ... <dst>]
	[-copyToLocal [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-count [-q] [-h] [-v] [-x] <path> ...]
	[-cp [-f] [-p | -p[topax]] <src> ... <dst>]
	[-df [-h] [<path> ...]]
	[-du [-s] [-h] [-x] <path> ...]
	
### 7.1.4 snapshot
	[-createSnapshot <snapshotDir> [<snapshotName>]]
	[-deleteSnapshot <snapshotDir> <snapshotName>]
```
[~]$ hadoop fs -createSnapshot  appendToFile/ bk_test
createSnapshot: Directory is not a snapshottable directory: /user/bokun.wang/appendToFile
```

### 7.1.5 expunge 清空回收站
	[-expunge]
	```
	hadoop fs -expunge
	```
	
	[-find <path> ... <expression> ...]
	[-get [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
	[-getfacl [-R] <path>]
	[-getfattr [-R] {-n name | -d} [-e en] <path>]
	[-getmerge [-nl] <src> <localdst>]
	[-help [cmd ...]]
	[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [<path> ...]]
	[-mkdir [-p] <path> ...]
	[-moveFromLocal <localsrc> ... <dst>]
	[-moveToLocal <src> <localdst>]
	[-mv <src> ... <dst>]
	[-put [-f] [-p] [-l] <localsrc> ... <dst>]
	[-renameSnapshot <snapshotDir> <oldName> <newName>]
	[-rm [-f] [-r|-R] [-skipTrash] <src> ...]
	[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
	[-setfacl [-R] [{-b|-k} {-m|-x <acl_spec>} <path>]|[--set <acl_spec> <path>]]
	[-setfattr {-n name [-v value] | -x name} <path>]
	[-setrep [-R] [-w] <rep> <path> ...]
	[-stat [format] <path> ...]
	[-tail [-f] <file>]
	[-test -[defsz] <path>]
	[-text [-ignoreCrc] <src> ...]
	[-touchz <path> ...]
	[-usage [cmd ...]]
 
## 7.2 hdfs File ACL


```

#修改历史数据读
hdfs dfs -setfacl -m  -R  group:$user:r-x  /xxx 


#修改default，后进入新数据读
hdfs dfs -setfacl -m -R  default:group:$user:r-x /xx

```


# Q&&A
## 1. REVISION_ID' doesn't exist in table
数据库问题:
https://community.cloudera.com/t5/Cloudera-Manager-Installation/MySQLSyntaxErrorException-Key-column-REVISION-ID-doesn-t/td-p/69621

```
2018-09-11 19:06:30,890 FATAL main:org.hsqldb.cmdline.SqlFile: SQL Error at 'UTF-8' line 57:
"alter table ROLE_CONFIG_GROUPS
    drop column REVISION_ID"
Key column 'REVISION_ID' doesn't exist in table
2018-09-11 19:06:30,890 FATAL main:org.hsqldb.cmdline.SqlFile: Rolling back SQL transaction.
2018-09-11 19:06:30,892 ERROR main:com.cloudera.enterprise.dbutil.SqlFileRunner: Exception while executing ddl scripts.
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Key column 'REVISION_ID' doesn't exist in table
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
```



 MariaDB 10.2.12
解决办法：

```
# 添加83 84两行内容
vim  /opt/cloudera/cm/schema/mysql/05003_cmf_schema.mysql.ddl

 80 alter table CONFIGS
 81     drop column REVISION_ID;
 82
 83 ALTER TABLE ROLE_CONFIG_GROUPS DROP INDEX IDX_UNIQUE_ROLE_CONFIG_GROUP;
 84 ALTER TABLE ROLE_CONFIG_GROUPS DROP INDEX IDX_ROLE_CONFIG_GROUP_CONFIG_REVISION;
 85
 86 alter table ROLE_CONFIG_GROUPS
 87     drop column REVISION_ID;

```


```
然后执行这两步骤就可以通过了
CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;
sh -x /opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h $IP   --scm-host $IP scm scm scm


以上两步同：
/opt/cloudera/cm/schema/scm_prepare_database.sh mysql -h $IP -u$USER -p$PW --scm-host $IP scm scm scm
```

## 2 FK_SERVICE_CONFIG_REVISION; check that it exists


```
cm服务启动失败
#错误日志
2018-12-26 18:09:31,359 FATAL main:org.hsqldb.cmdline.SqlFile: SQL Error at 'UTF-8' line 2:
"alter table SERVICES
    drop foreign key FK_SERVICE_CONFIG_REVISION"
Can't DROP FOREIGN KEY `FK_SERVICE_CONFIG_REVISION`; check that it exists
2018-12-26 18:09:31,360 ERROR main:com.cloudera.enterprise.dbutil.SqlFileRunner: Exception while executing ddl scripts.
com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: Can't DROP FOREIGN KEY `FK_SERVICE_CONFIG_REVISION`; check that it exists
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	
```


```
#【解决办法】
#http://community.cloudera.com/t5/Cloudera-Manager-Installation/Foreign-Key-issue-creating-SCM-repository-in-MySQL-database/td-p/2523

alter the ddl scripts in /usr/share/cmf/schema/mysql directory

You will need to add two lines:

After the first update add 

SET FOREIGN_KEY_CHECKS=0;

Then at the bottom of the file add 

SET FOREIGN_KEY_CHECKS=1;

 

You will need to do that to the following files: 

00035_cmf_schema.mysql.ddl
00043_cmf_schema.mysql.ddl
04509_cmf_schema.mysql.ddl
04511_cmf_schema.mysql.ddl
```
## 3  ExitCodeException exitCode=24: Invalid conf file provided : /etc/hadoop/conf.cloudera.yarn/container-executor.cfg

```
INFO org.apache.hadoop.service.AbstractService: Service NodeManager failed in state INITED; cause: org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor
org.apache.hadoop.yarn.exceptions.YarnRuntimeException: Failed to initialize container executor
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:269)
        at org.apache.hadoop.service.AbstractService.init(AbstractService.java:163)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:562)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:609)
Caused by: java.io.IOException: Linux container executor not configured properly (error=24)
        at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:199)
        at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:267)
        ... 3 more
Caused by: ExitCodeException exitCode=24: Invalid conf file provided : /etc/hadoop/conf.cloudera.yarn/container-executor.cfg
```
【解决办法】

![-w1028](/assets/img/15482342524898.jpg)

```
$chmod 6050 ./cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop-yarn/bin/container-executor
---Sr-s---. 1 root yarn 53728 8月  10 02:14 ./cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop-yarn/bin/container-executor
----r-x---. 1 root yarn 53728 1月  23 16:31 ./cloudera/parcels/CDH-5.15.1-1.cdh5.15.1.p0.4/lib/hadoop-yarn/bin/container-executor.20190123
```