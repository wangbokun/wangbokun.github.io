---
layout: post
category: 大数据
---

# 1 OverView
> https://support.huawei.com/enterprise/zh/doc/EDOC1000113254?section=j00d
## 1.1 数据格式parquet
# 2 HDFS Site

key | default value| 建议值|说明|
---|---|---|---|---
dfs.block.size | |134217728|128MB|
dfs.replication ||3|副本数|
dfs.datanode.du.reserved ||10737418240【10G】|磁盘预留空间，根据磁盘大小自己定义|
dfs.namenode.handler.count||设置该值的一般原则是将其设置为集群大小的自，然对数乘以20，即20logN，N为集群大小,N表示集群大小 比如50个节点的集群,python -c 'import math ; print int(math.log(50) * 20)',78|*NameNode有一个工作线程池用来处理客户端的远程过程调用及集群守护进程的调用。处理程序数量越多意味着要更大的池来处理来自不同DataNode的并发心跳以及客户端并发的元数据操作。对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10|
dfs.datanode.max.xcievers||65536|NameNode同时和DataNode通信的线程数|
dfs.balance.bandwidthPerSec||20485760|默认我1048579（1MB/S）,将其增大为20MB/S|
dfs.datanode.failed.volumes.tolerated|0|2|声明失败前允许多少个硬盘出现故障，服务依然运行|
   ||||
    ||||
     ||||

# 3 Core Site

key | default value| 建议值|说明|
---|---|---|---|---
fs.trash.interval |  |1440分钟=60\*24|检查点被删除后的分钟数|
fs.trash.checkpoint.interval |  |1440分钟=60\*24|垃圾检查点之间的分钟数|
io.file.buffer.size|4096|建议1M|默认4K，以提升 hdfs io |
io.bytes.per.checksum||512|每次进行校验和检查的字节数。一定不能大于io.file.buffer.size.|
 ||||
  ||||
 
 
# 4 balancer
## 4.1 balancer policy
 
```
dfs.datanode.fsdataset.volume.choosing.policy
循环（round-robin）策略将新块均匀分布在可用磁盘上；
而可用空间（ available-space ）策略优先将数据写入具有最大可用空间的磁盘（通过百分比计算的）
```
 
 ![](/assets/img//15749986010461.jpg)


```
Rebalancing Policy
Balancer Default Group 
DataNode
BlockPool
```

![](/assets/img//15749986961024.jpg)

## 4.2 node balancer
## 4.3 disk balancer
 - 配置修改. hdfs->configuration->filters(scope->hdfs(service-wide))->Cluster-wide Advanced Configuration Snippet (Safety Valve) for core-site.xml 
 
```
dfs.disk.balancer.enabled
true
```

![-w438](/assets/img//15749983283641.jpg)
![-w874](/assets/img//15749983397553.jpg)


```
修改完之后，重启集群.
hdfs diskbalancer -plan xx.dn.001.xx.com
#参考https://www.iteblog.com/archives/1905.html， 等重启完集群后，在做验证
```