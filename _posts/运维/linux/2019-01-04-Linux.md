---
layout: post
category: 运维
---


# 1. Command
## 1.1 ssh
```
#Proxy
ssh -fTnN -p 2222 -i /root/.ssh/key -D 0.0.0.0:8157 $User@$Ip
```
## 1.2 Git

|  名称| 命令 |备注  |
| --- | --- | --- |
| 强制提交 | git push -u origin dev -f |  |
|checkout分支|git checkout dev|
|Pull分支|git pull origin dev|
|查看本地分支|git branch||
|查看远程分支|git branch -a||
|提交远程分支|git push origin test  |
|删除远程分支|git branch -r -d origin/branch-name |


```
## 基本配置
git config --global core.editor vim
git config --global user.name 'USERNAME'
git config --global user.email 'Email_Address'
git config --global color.ui true
git config --global alias.st status
git config --global alias.co checkout
git config --global alias.ci commit
git config --global alias.cl clone
git config --global alias.br branch
git config --global alias.di diff
git config --global alias.unstage 'reset HEAD'
git config --global alias.last 'log -1'
git config --global core.autocrlf false # 禁止自动将 LF 转换为 CRLF

## 查看 config
git config --list
```

- git基本用法


```
### 克隆远程仓库
git clone remote_addr                                       # 克隆remote版本库
git clone -o jQuery https://github.com/xxx/xxx.git    # 指定remote_name为jQuery，默认origin

### 添加文件至暂存区
git add files/dirs      # 添加文件(夹)至暂存区index
git add -A              # 添加所有文件(夹)至index

### 提交暂存区文件至版本库
git commit -m 'init'    # 提交暂存区文件至版本库
git commit -a -m '...'  # commit所有修改了的文件，没有加入暂存区的文件不会被commit

### 查看当前状态
git status              # 查看状态

### diff 比较文件差异
git diff
git diff file                   # 工作区 vs 暂存区，如果还没add到暂存区，则 工作区 vs 最新版本库
git diff dev
git diff dev file               # 工作区 vs dev分支
git diff --cached file          # 暂存区 vs 最新版本库
git diff --cached HEAD~2 file   # 暂存区 vs 最近的倒数第2次版本库
git diff --cached commit_id file# 暂存区 vs commit_id版本
git diff HEAD~2|commit_id file  # 工作区 vs 指定版本库
git diff commit_id commit_id    # 版本库 vs 版本库

### log 查看日志
git log                         # 查看log
git log -3                      # 查看最近3次commit的log
git log --oneline               # 每个commit放在一行
git log --pretty=oneline        # 完整显示commit_id 
git log --graph                 # 查看分支图形
git log --oneline --graph
git log -p                      # 同时显示diff信息
git log dev                     # 查看dev分支log
git log origin/master           # 查看origin/master分支log
git log -p master FETCH_HEAD    # 比较master分支与fetch最新分支
git reflog                      # 查看操作记录，可查看所有commit_id

### 查看暂存区文件
git ls-files                # 查看暂存区文件
git ls-files -s             # 查看暂存区文件

### 删除暂存区文件
git rm file                 # 删除暂存区和工作区文件
git rm --cached file        # 删除暂存区文件
git commit -m '...'         # 提交至版本库

### branch 分支
git checkout -b dev         # 创建dev分支并切换到dev分支
# 相当于
git branch dev              # 创建 dev 分支
git checkout dev            # 切换至 dev 分支

### 查看分支
git branch          # 查看当前分支
git branch -a|-r    # 查看所有|远程分支

### 操作分支
git checkout master
git merge dev       # 合并dev分支到当前分支(master)
git branch -d dev   # 删除dev分支

git merge --no-ff -m '...' dev  # 保留dev分支信息(关闭fast forward模式),其实就是新建一个提交

### 保存暂存区文件
git stash               # 保存暂存区文件至一个临时位置(常用于修复bug)
git stash list          # 查看
git stash apply name    # 恢复现场
git stash pop name      # 恢复现场(删除stash)

### 删除分支
git branch -D dev       # 强制删除未合并的分支

### 建立分支追踪关系
git branch --set-upstream master origin/master  # 手动建立分支追踪关系，clone操作默认会建立分支追踪关系

### 远程仓库操作
git remote add origin https://github.com/zfl9/test.git  # 添加remote主机
git remote
git remote -v
git remote show origin
git remote rm origin                    # 删除remote主机
git remote rename origin github_test    # 重命名remote主机

# 需要同步多个远程仓库时，可以用这种方法，只要push一次，就把所有的远程仓库都同步了
git remote set-url --add origin git@git.coding.net:zfl9/vim.git  # 添加url
git remote set-url --del origin git@git.coding.net:zfl9/vim.git  # 删除url

### git fetch/pull
# git fetch是从remote拉取最新的commit,然后手动merge合并
# git pull是从remote拉取最新的commit并进行merge合并(不安全)

# fetch & merge
git fetch origin master         # 从origin拉取master分支
git fetch origin dev            # 从origin拉取dev分支
git fetch origin tag v1.0       # 从origin拉取tag

git log -p master origin/master # 查看log及diff

git merge origin/master         # 合并origin/master分支到当前分支
git merge FETCH_HEAD            # 同上
# 或者
git fetch origin master:temp    # 从origin拉取master分支,并在本地将其创建为temp分支
git log -p master temp
git merge temp
git branch -d temp

git branch -dr origin/master    # 删除fetch的远程分支origin/master

# pull
usage: git pull remote_name remote_branch:local_branch
git pull origin test:dev        # 拉取origin的test分支,并与本地dev分支合并
git pull origin master          # 拉取origin的master分支,并与当前分支合并
git pull origin                 # 如果当前分支存在追踪关系,则可以省略分支名
git pull                        # 如果当前分支只有一条追踪关系,则还可以省略remote主机名

# push
usage: git push remote_name local_branch:remote_branch
## branch
git push origin test:dev        # 推送test分支到remote的dev分支
git push origin master          # 推送master分支至与之存在追踪关系的remote分支
git push -u aliyun master       # 指定master分支默认remote主机为aliyun(当存在多条追踪关系时)
git push origin                 # 如果当前分支存在追踪关系,则可以省略分支名
git push                        # 如果当前分支只有一条追踪关系,则还可以省略remote主机名
git push origin :master         # 删除远程分支
git push --delete origin master # 同上
git push --all origin           # 推送本地所有分支到origin主机

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
git v2.0 之前默认是推送全部分支到远程分支，"matching"方式
git v2.0 之后默认是推送当前分支到远程分支，"simple"方式

# 修改默认push方式
git config --global push.default matching
or
git config --global push.default simple
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

## tag
git push origin tag_name    # 推送tag
git push origin --tags      # 推送所有tag

git tag v1.0        # 打在最新的commit上
git tab v2.0 3f89   # 打在指定的commit上
git tag -a tag_name -m '...' # 含备注的tag

git tag             # 查看tag
git tag -l
git show tag_name

git tag -d v1.0                     # 删除本地tag
git push --delete origin tag v1.0   # 删除远程tag

git checkout -b dev v1.0    # 检出tag v1.0到新分支dev
git checkout v1.0           # 检出tag v1.0到工作区,但是不能修改,若要修改请用上面的方式
```
- git将master分支代码合并到自己的分支


```
git checkout master
git pull
git checkout bokun.wang
git merge master
git push origin  bokun.wang
```

- git恢复操作详解

![](/assets/img//15889226630826.jpg)


```
# 暂存区 -> 工作区
# 恢复工作区的文件至暂存区状态(如果工作区文件没有add到暂存区,则恢复最新版本库的文件到工作区)
git checkout -- .       # 全部file
git checkout -- file    # 指定file

# 版本库 -> 暂存区
# 恢复暂存区的文件至版本库状态
git reset --soft            # 默认参数就是--soft,可以省略
git reset                   # 全部file
git reset file              # 指定file
git reset HEAD~2            # 指定commit
git reset Commit_ID         # 指定commit

# 版本库 -> 暂存区&工作区
# 恢复工作区和暂存区的文件至版本库状态
git checkout HEAD~2
git checkout HEAD~2 file
git checkout Commit_ID
git checkout Commit_ID file

git reset --hard
git reset --hard HEAD~2
git reset --hard HEAD~2 file
git reset --hard Commit_ID
git reset --hard Commit_ID file
```
## 1.3  alias

```
alias cp='cp -i'
alias egrep='egrep --color=auto'
alias fgrep='fgrep --color=auto'
alias grep='grep --color=auto'
alias l.='ls -d .* --color=auto'
alias ll='ls -l --color=auto'
alias ls='ls --color=auto'
alias mv='mv -i'
alias rm='rm -i'
alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'
```

## 1.4 awk

```
#截取第N列之后所有列的数据
cat filename | awk -F " "  '{for (i=4;i<=NF;i++)printf("%s ", $i);print ""}'
```
## 1.5 history

```
HISTCONTROL=ignorespace #忽略所有一空格开头的命令，执行一条命令前面加个空格，命令可正常执行，但是history不记录
HISTCONTROL=erasedups   # 删除重复命令
export HISTSIZE=3000
export HISTTIMEFORMAT="%F %T " #显示执行时间
```
## 1.6 NFS

```
yum -y install nfs-utils rpcbind    # 客户端也要安装，未安装可能会导致无法挂载 nfs
#配置 NFS
vim /etc/exports
--- exports ---
/share *(rw,sync,no_root_squash,no_subtree_check)
--- exports ---

## 解释如下
*               代表所有主机都可以访问nfs。也可以写具体的ip，网段，域名
/share          共享目录的绝对路径
rw              读写权限
sync            数据实时同步写入磁盘
no_root_squash      root用户具有根目录的完全管理访问权限
no_subtree_check    不检查父目录权限 

## 常用参数
ro                  只读访问
rw                  读写访问
sync                所有数据在请求时写入共享
async               NFS在写入数据前可以相应请求
secure              NFS通过1024以下的安全TCP/IP端口发送
insecure            NFS通过1024以上的端口发送
wdelay              如果多个用户要写入NFS目录，则归组写入（默认）
no_wdelay           如果多个用户要写入NFS目录，则立即写入，当使用async时，无需此设置。
hide                在NFS共享目录中不共享其子目录
no_hide             共享NFS目录的子目录
subtree_check       如果共享/usr/bin之类的子目录时，强制NFS检查父目录的权限（默认）
no_subtree_check    和上面相对，不检查父目录权限
all_squash          共享文件的UID和GID映射匿名用户anonymous，适合公用目录。
no_all_squash       保留共享文件的UID和GID（默认）
root_squash root    用户的所有请求映射成如anonymous用户一样的权限（默认）
no_root_squash root 用户具有根目录的完全管理访问权限
anonuid=xxx         指定NFS服务器/etc/passwd文件中匿名用户的UID
anongid=xxx         指定NFS服务器/etc/passwd文件中匿名用户的GID

## nfs相关端口
portmap(rpcbind) (tcp/udp/111)、nfs (tcp/udp/2049)、其他动态调用小于1024未使用的端口

## 如果修改了/etc/exports文件, 不需要重新激活nfs，只要重新扫描一次/etc/exports文件，并且重新将设定加载即可：
exportfs [-aruv]
参数说明:
-a  全部挂载（或卸载）/etc/exports文件内的设定
-r  重新挂载/etc/exports中的设置，此外同步更新/etc/exports及/var/lib/nfs/xtab中的内容
-u  卸载某一目录
-v  在export时将共享的目录显示在屏幕上

运行 NFS
CentOS 6.x

chkconfig rpcbind on
chkconfig nfs on
service rpcbind start   # 先运行 rpcbind
service nfs start
BashCopy
CentOS 7.x

systemctl enable rpcbind
systemctl enable nfs-server # 注意是 "nfs-server"
systemctl start rpcbind
systemctl start nfs-server

挂载 NFS
## 挂载 NFS，然后就可以像本地磁盘一样访问了
mount -t nfs 127.0.0.1:/share /mnt

## 查看 NFS-Server 共享目录
showmount -e 127.0.0.1  # 查看服务器的共享目录

## 开机启动挂载，写入 fstab 即可
192.168.1.100:/share /mnt nfs defaults 0 0
```
## 1.7 rm -rf 

```
#解决rm -rf 无回收站问题

pip install trash-cli -i https://pypi.tuna.tsinghua.edu.cn/simple

trash-put：将文件移至回收站；
trash-list：查看回收站中的文件；
trash-restore：从回收站中找回被删的文件；
trash-rm：删除回收站中的单个文件；
trash-empty：清空回收站中的所有文件；

# 编辑 /etc/profile.d/trash-cli.sh
vim /etc/profile.d/trash-cli.sh

# 设置命令别名
alias rm='trash-put'
alias rm.list='trash-list'
alias rm.restore='trash-restore'
alias rm.delete='trash-rm'
alias rm.empty='trash-empty'

# :wq 保存退出，然后让其生效
source /etc/profile
```
## 1.8 find

```
### 文件名 name
find . -name "*.txt"

### 文件大小 size
find . -size 1k     # 等于 1 kb
find . -size +1k    # 大于 1 kb
find . -size -1k    # 小于 1 kb
find . -empty       # 空文件（夹）

### 权限 perm
find . -perm 777

### 类型 type
# b      块设备，block (buffered) special
# c      字符设备，character (unbuffered) special
# d      目录文件，directory
# f      普通文件，regular file
# l      符号链接，symbolic link; this is never true if the -L option or the -follow option is in effect, unless the symbolic link is  broken. If you want to search for symbolic links when -L is in effect, use -xtype.
# p      命名管道，named pipe (FIFO)
# s      套接字文件，socket
find . -type d  # 查找目录文件
find . -type f  # 查找普通文件
find . -type l  # 查找链接文件

### 所属用户/组
find . -user root       # 所属用户
find . -group root      # 所属组
find . -uid|gid 0       # uid|gid 为 0
find . -nouser|nogroup  # 其他用户|其他用户组

### 正则 regex
find . -regex ".*\.txt"     # 搜索 .txt 文件

### 正则 iregex（忽略大小写）
find . -iregex ".*\.TXT"    # 忽略大小写

### 时间 time
# atime - access time，访问时间
# mtime - modify time，修改时间（内容修改）
# ctime - change time，改变时间（属性修改）
find . -atime 1     # 查找昨天访问的文件、文件夹
find . -atime +1    # 查找昨天以前（含）访问的文件、文件夹
find . -atime -1    # 查找昨天以来（含）访问的文件、文件夹
find . -amin 1      # 同上，单位为 min 分钟
find . -ctime 1     # 同上，属性修改时间
find . -mtime 1     # 同上，内容修改时间

### 搜索深度 maxdepth
find . -maxdepth 1 -name "*.txt"    # 仅查找当前文件夹下的 .txt，不进行递归查找

### 逻辑连接符
find . -type f -size -10k       # 默认为逻辑与
find . -type f -o -size -10k    # -o 表示逻辑或
find . ! -type f                # ! 表示逻辑非

### 执行动作 exec
find . -name '*.txt' -exec tar czvf txt.tar.gz {} \;
# {} 代表 find 查找到的文件，此处为所有 .txt 文件
# \; 为命令结束符，为防止与 shell 分号混淆，需要使用转义
```
## 1.9 grep

```
### 常用参数
# 模式：
# -G, --basic-regexp        基本正则（默认）
# -E, --extended-regexp     扩展正则（egrep）
# -P, --perl-regexp         Prel 正则
# -e, --regexp=PATTERN      指定多个正则模式时使用
# -f, --file=FILE           从文件中读取正则模式
# -i, --ignore-case         忽略大小写
# -w, --word-regexp         匹配单词
# -x, --line-regexp         匹配单行
#
# 杂项：
# -s, --no-messages         抑制错误信息
# -v, --invert-match        反向匹配
# 
# 输出：
# -m, --max-count=NUM       最多匹配 NUM 行
# -b, --byte-offset         显示字节偏移数
# -n, --line-number         显示所在行数
# -H, --with-filename       显示所属文件
# -h, --no-filename         不显示所属文件
# -o, --only-matching       显示匹配内容而不是整行
# -q, --quiet, --silent     抑制所有正常输出
# -d, --directories=ACTION  定义如何处理目录：read|recurse|skip
# -D, --devices=ACTION      定义如何处理设备文件/管道文件/套接字文件：read|skip
# -r, --recursive           等同于 '--directories=recurse'
# -R, --dereference-recursive   同 -r，但是会跟随符号链接
#     --include=FILE_PATTERN    只查找与模式相匹配的文件
#     --exclude=FILE_PATTERN    跳过与模式相匹配的文件和文件夹
#     --exclude-from=FILE       跳过与模式相匹配的文件
#     --exclude-dir=PATTERN     跳过与模式相匹配的文件夹
# -l, --files-with-matches  打印匹配的文件，而非文件内容
# -L, --files-without-match 打印不匹配的文件，而非文件内容
# -c, --count               打印匹配到的行数，而非文件内容
# -T, --initial-tab         使用 tab 分隔输出项
#     --color[=WHEN]        高亮显示匹配项：always|never|auto
# 
# 上下文：
# -B, --before-context=NUM  打印匹配行的前 NUM 行
# -A, --after-context=NUM   打印匹配行的后 NUM 行
# -C, --context=NUM         打印匹配行的前后 NUM 行
# -NUM                      等同于 '--context=NUM'

### 命令举例
grep -i 'nginx' /etc/passwd                     # 查找 nginx 用户
ls -l /etc/ | grep -v '^total' | grep -c '^d'   # 统计有多少个目录
```
## 1.10 xargs

```
xargs 是给其他命令传递命令行参数的过滤器，擅长分割命令行参数，并将其传递给对应命令；
xargs 默认从标准输入中读取数据，然后进行参数处理；使用 -a 参数可让 xargs 从文件中读取；
如果没有指定要执行的命令，则 xargs 默认将其传递给 echo，而 echo 会将传递的参数打印出来。

### 常用参数
# -a, --arg-file=FILE          从文件中读取输入参数，而非标准输入
# -d, --delimiter=CHARACTER    指定输入参数的分割符，默认为空白符（多个空格合并）
# -i, --replace[=R]            指定参数替换符，如果指定为空，默认为 '{}'
# -I R                         等同于 '--replace=R'
# -n, --max-args=MAX-ARGS      每次给 COMMAND 传递 MAX-ARGS 个参数，默认传递全部
# -P, --max-procs=MAX-PROCS    同时启动 MAX-PROCS 个 COMMAND 进程，默认为 1，如果为 0，则启动尽可能多的进程
# -p, --interactive            在运行 COMMAND 命令前提示用户
# -r, --no-run-if-empty        如果参数为空，则不执行 COMMAND，默认至少执行一次
# -t, --verbose                在执行 COMMAND 命令前打印要执行的命令及参数

### 命令举例
echo '1;2;3;4;5' | xargs -d';' -n1
1
2
3
4
5

# 批量执行命令 - 软链接
# root @ arch in ~ [14:01:32]
$ ls

# root @ arch in ~ [14:01:33]
$ mkdir dist

# root @ arch in ~ [14:01:36]
$ touch lib{A..G}.so

# root @ arch in ~ [14:01:38]
$ ls
dist  libA.so  libB.so  libC.so  libD.so  libE.so  libF.so  libG.so

# root @ arch in ~ [14:01:39]
$ ls | grep '\.so' | xargs -n1 -i'ARG' ln -sf $(pwd)/ARG dist/ARG

# root @ arch in ~ [14:02:05]
$ ls
dist  libA.so  libB.so  libC.so  libD.so  libE.so  libF.so  libG.so

# root @ arch in ~ [14:02:08]
$ ll dist
total 0
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libA.so -> /root/libA.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libB.so -> /root/libB.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libC.so -> /root/libC.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libD.so -> /root/libD.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libE.so -> /root/libE.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libF.so -> /root/libF.so
lrwxrwxrwx 1 root root 13 Nov 22 14:02 libG.so -> /root/libG.so
```
## 1.11 sort

```
### 常用参数
# 排序选项：
# -b, --ignore-leading-blanks   忽略前导空白
# -f, --ignore-case             忽略大小写
# -d, --dictionary-order        只考虑空格、字母、数字
# -i, --ignore-nonprinting      只考虑可打印字符
# -n, --numeric-sort            进行数值排序（字符字面值）
# -g, --general-numeric-sort    进行数值排序（支持科学记数法）
# -V, --version-sort            进行版本排序（e.g, 软件版本）
# -M, --month-sort              进行月份排序（unknown）
# -h, --human-numeric-sort      进行单位排序（SIZE; e.g., 2K 1G）
# -R, --random-sort             使用随机排序
# -r, --reverse                 使用反向排序
#
# 其他选项：
# -u, --unique                  在标准输出中去除重复行
# -o, --output=FILE             将标准输出写入至文件，不能直接使用重定向符
# -t, --field-separator=SEP     指定分割符，默认为空白符，常用 -k 结合使用
# -k, --key=KEYDEF              使用给定 key 进行排序（KEYDEF）
#
# SIZE 单位：
# 百分比：%
# 大小单位：b、K(default)、M、G、T、P、E、Z、Y；
#
# KEYDEF 格式："F[.C][OPTS][,F[.C][OPTS]]"
# "F"：字段序号，从 1 开始
# "C"：字段内序号，从 1 开始
# "OPTS"：[bdfgiMhnRrV]，即短选项字符
# 可以有两个 "F[.C][OPTS]"，定义开始和结束边界，如果没有结束边界，则默认匹配至行尾

### 命令举例
sort file           # 升序排序
sort -r file        # 降序排序
sort -f file        # 忽略大小写
sort -n file        # 按数值升序排序
sort -u file        # 删除重复行（不改变原文件）
sort file -o file   # 将排序结果写入文件，使用重定向将导致文件被清空

### 进阶用法
# 测试文件
$ cat data.txt
baidu:200:6000
google:450:8000
bing:300:7200
sogou:120:4000
sina:150:4500

# 按照公司名排序
$ cat data.txt | sort
baidu:200:6000
bing:300:7200
google:450:8000
sina:150:4500
sogou:120:4000

# 按照公司人数排序
$ cat data.txt | sort -t':' -k2n
sogou:120:4000
sina:150:4500
baidu:200:6000
bing:300:7200
google:450:8000

# 按照薪资排序
$ cat data.txt | sort -t':' -k3n
sogou:120:4000
sina:150:4500
baidu:200:6000
bing:300:7200
google:450:8000

# 按照公司名首字母排序，相同的再以工资降序排序
$ cat data.txt | sort -t':' -k1.1,1.1 -k3nr
bing:300:7200
baidu:200:6000
google:450:8000
sina:150:4500
sogou:120:4000
```
## 1.12 uniq

```
### 常用参数
# -i, --ignore-case     忽略大小写
# -c, --count           显示相同行的数目
# -u, --unique          打印未重复行
# -d, --repeated        打印重复行
# -D                    打印所有重复行

### 命令举例
sort test.txt | uniq    # 消除重复行
sort test.txt | uniq -c # 统计重复行出现次数
sort test.txt | uniq -d # 找出重复行
```
## 1.13 tr

```
tr 即 translate，翻译、转换；tr 只处理标准输入，如果需要处理文件请使用重定向；

tr [OPTION]... SET1 [SET2]
### 常用参数
# -c, -C, --complement    使用 SET1 的补码（即不在集合中的字符）
# -d, --delete            删除 SET1 中的字符
# -s, --squeeze-repeats   合并连续的重复字符，在合并多个空格时很有用，此时 SET2 无效
#
# SET 集合：
# \\              反斜杠
# \a              响铃
# \b              退格
# \r              回车
# \n              换行
# \f              换页
# \t              水平制表
# \v              垂直制表
# \NNN            八进制数字（1~3 位）
# CHAR1-CHAR2     字符/数字范围
# [:alpha:]       字母
# [:digit:]       数字
# [:alnum:]       字母 + 数字
# [:lower:]       小写字母
# [:upper:]       大写字母
# [:cntrl:]       控制符
# [:print:]       可打印字符，包括空格
# [:graph:]       可显示字符，不包括空格
# [:punct:]       标点符号
# [:blank:]       空白符
# [:space:]       水平或垂直空白
# [:xdigit:]      十六进制数字

### 命令举例
tr 'a-z' 'A-Z' < test.txt   # 大小写转换
tr ' ' '\t' < test.txt      # 空格转换为 tab
tr -s ' ' ' ' < test.txt    # 合并连续空格
tr -d ' ' < test.txt        # 删除所有空格
```

## 1.14 cut

```
cut 的工作就是”剪”，就是在文件中负责裁剪数据；cut 是以每一行为一个处理对象的；
cut 一般以什么为依据呢？也就是说，我怎么告诉 cut 我想定位到的剪切内容呢？三种方式：

字节 byte：选项 -b
字符 char：选项 -c
字段 field：选项 -f
### 字节
echo 'abcdefg' | cut -b 2       # 获取第二个字节；"b"
echo 'abcdefg' | cut -b 2,4-6   # 获取第二个字节和第 4-6 个字节，类似用法下同；"bdef"
echo 'abcdefg' | cut -b -3      # 获取开头至第三个字节，即前三个字节，类似用法下同；"abc"
echo 'abcdefg' | cut -b 3-      # 获取第三个字节至行尾，类似用法下同；"cdefg"

### 字符
echo 'abcdefg' | cut -c 2       # "b"

### 字段
head -5 /etc/passwd | cut -d':' -f1     # -d 指定分割符，-f 指定字段号
```
## 1.15 paste

```
这个很简单，和 cut 的原理几乎一样，就是将几个文件的相应行用制表符连接起来，并打印至标准输出；

# root @ arch in ~ [16:07:24]
$ cat a
1
2
3

# root @ arch in ~ [16:07:26]
$ cat b
a
b
c

# root @ arch in ~ [16:07:27]
$ paste a b
1    a
2    b
3    c

# root @ arch in ~ [16:07:36]
$ paste a b | sed -n l
1\ta$
2\tb$
3\tc$

# root @ arch in ~ [16:07:56]
$ paste -d':' a b
1:a
2:b
3:c

# root @ arch in ~ [16:08:24]
$ paste -d':' -s a b
1:2:3
a:b:c
```
## 1.16 column

```
-t：创建一个表，然后输出（常用）
-s sep：输入中列与列之间的分隔符，默认空白符
-o str：输出中列与列之间的分隔符，默认两空格

文本格式化工具（创建表），先看看怎么用：

# root @ arch in ~ [11:03:08] 
$ cat /etc/passwd
root:x:0:0:root:/root:/bin/zsh
bin:x:1:1:bin:/bin:/usr/bin/nologin
daemon:x:2:2:daemon:/:/usr/bin/nologin
mail:x:8:12:mail:/var/spool/mail:/usr/bin/nologin
ftp:x:14:11:ftp:/srv/ftp:/usr/bin/nologin
http:x:33:33:http:/srv/http:/usr/bin/nologin
nobody:x:99:99:nobody:/:/usr/bin/nologin
systemd-journal-gateway:x:191:191:systemd-journal-gateway:/:/usr/bin/nologin
systemd-timesync:x:192:192:systemd-timesync:/:/usr/bin/nologin
systemd-network:x:193:193:systemd-network:/:/usr/bin/nologin
systemd-bus-proxy:x:194:194:systemd-bus-proxy:/:/usr/bin/nologin
systemd-resolve:x:195:195:systemd-resolve:/:/usr/bin/nologin
systemd-journal-remote:x:998:998:systemd Journal Remote:/:/sbin/nologin
dbus:x:81:81::/:/sbin/nologin
uuidd:x:68:68::/:/sbin/nologin
systemd-journal-upload:x:996:996:systemd Journal Upload:/:/sbin/nologin
systemd-coredump:x:997:997:systemd Core Dumper:/:/sbin/nologin
git:x:995:995:git daemon user:/:/usr/bin/git-shell
privoxy:x:42:42:Privoxy:/:/sbin/nologin
nginx:x:1000:1000::/home/nginx:/sbin/nologin
dhcp:x:993:993:DHCP daemon:/:/sbin/nologin
zfl9:x:1001:1001::/home/zfl9:/bin/zsh
pdnsd:x:992:992:Proxy DNS server:/var/cache/pdnsd:/sbin/nologin
dnsmasq:x:991:991:dnsmasq daemon:/:/sbin/nologin
mysql:x:990:990:MariaDB:/var/lib/mysql:/sbin/nologin

# root @ arch in ~ [11:03:09] 
$ cat /etc/passwd | column -t -s:
root                     x  0     0     root                     /root             /bin/zsh
bin                      x  1     1     bin                      /bin              /usr/bin/nologin
daemon                   x  2     2     daemon                   /                 /usr/bin/nologin
mail                     x  8     12    mail                     /var/spool/mail   /usr/bin/nologin
ftp                      x  14    11    ftp                      /srv/ftp          /usr/bin/nologin
http                     x  33    33    http                     /srv/http         /usr/bin/nologin
nobody                   x  99    99    nobody                   /                 /usr/bin/nologin
systemd-journal-gateway  x  191   191   systemd-journal-gateway  /                 /usr/bin/nologin
systemd-timesync         x  192   192   systemd-timesync         /                 /usr/bin/nologin
systemd-network          x  193   193   systemd-network          /                 /usr/bin/nologin
systemd-bus-proxy        x  194   194   systemd-bus-proxy        /                 /usr/bin/nologin
systemd-resolve          x  195   195   systemd-resolve          /                 /usr/bin/nologin
systemd-journal-remote   x  998   998   systemd Journal Remote   /                 /sbin/nologin
dbus                     x  81    81                             /                 /sbin/nologin
uuidd                    x  68    68                             /                 /sbin/nologin
systemd-journal-upload   x  996   996   systemd Journal Upload   /                 /sbin/nologin
systemd-coredump         x  997   997   systemd Core Dumper      /                 /sbin/nologin
git                      x  995   995   git daemon user          /                 /usr/bin/git-shell
privoxy                  x  42    42    Privoxy                  /                 /sbin/nologin
nginx                    x  1000  1000                           /home/nginx       /sbin/nologin
dhcp                     x  993   993   DHCP daemon              /                 /sbin/nologin
zfl9                     x  1001  1001                           /home/zfl9        /bin/zsh
pdnsd                    x  992   992   Proxy DNS server         /var/cache/pdnsd  /sbin/nologin
dnsmasq                  x  991   991   dnsmasq daemon           /                 /sbin/nologin
mysql                    x  990   990   MariaDB                  /var/lib/mysql    /sbin/nologin
```
## 1.17 sed 
## 1.18 awk
## 1.19 iftop
  
```
#过滤网段流量
iftop -F x.x.x.x/掩码
```
## 1.20 alternatives


```
usage: alternatives --install <link> <name> <path> <priority>
                    [--initscript <service>]
                    [--family <family>]
                    [--slave <link> <name> <path>]*
       alternatives --remove <name> <path>
       alternatives --auto <name>
       alternatives --config <name>
       alternatives --display <name>
       alternatives --set <name> <path>
       alternatives --list
       
# 切换spark版本       
update-alternatives --config spark2.4.6-shell
There are 3 programs which provide 'spark2.4.6-shell'.

  Selection    Command
-----------------------------------------------
*  1           /usr/bin/spark2.4.6-shell
 + 2           /data/cloudera/parcels/spark2.4.6/bin/spark-shell
   3           /data/cloudera/parcels/spark2.4.6/bin/spark2.4.6-shell
Enter to keep the current selection[+], or type selection number: 2

#删除
alternatives --remove spark2.4.6-shell  /usr/bin/spark2.4.6-shell
```

## 1.21 update-alternatives 


```
用法：update-alternatives [<选项> ...] <命令>

命令：
  --install <链接> <名称> <路径> <优先级>
    [--slave <链接> <名称> <路径>] ...
                           在系统中加入一组候选项。
  --remove <名称> <路径>   从 <名称> 替换组中去除 <路径> 项。
  --remove-all <名称>      从替换系统中删除 <名称> 替换组。
  --auto <名称>            将 <名称> 的主链接切换到自动模式。
  --display <名称>         显示关于 <名称> 替换组的信息。
  --query <名称>           机器可读版的 --display <名称>.
  --list <名称>            列出 <名称> 替换组中所有的可用候选项。
  --get-selections         列出主要候选项名称以及它们的状态。
  --set-selections         从标准输入中读入候选项的状态。
  --config <名称>          列出 <名称> 替换组中的可选项，并就使用其中
                           哪一个，征询用户的意见。
  --set <名称> <路径>      将 <路径> 设置为 <名称> 的候选项。
  --all                    对所有可选项一一调用 --config 命令。

<链接>  是指向 /etc/alternatives/<名称> 的符号链接。 (如 /usr/bin/pager)
<名称>  是该链接替换组的主控名。(如 pager)
<路径>  是候选项目标文件的位置。（程序的实际路径）(如 /usr/bin/less)
<优先级>  是一个整数，在自动模式下，这个数字越高的选项，其优先级也就越高。

选项：
  --altdir <目录>          改变候选项目录。
  --admindir <目录>        设置 statoverride 文件的目录。
  --log <文件>             改变日志文件。
  --force                  就算没有通过自检，也强制执行操作。
  --skip-auto              在自动模式中跳过设置正确候选项的提示
                           (只与 --config 有关)
  --verbose                启用详细输出。
  --quiet                  安静模式，输出尽可能少的信息。不显示输出信息。
  --help                   显示本帮助信息。
  --version                显示版本信息。
  
 例子: 
update-alternatives --install /usr/bin/spark2.4.6-shell spark2.4.6-shell /data/cloudera/parcels/spark2.4.6/bin/spark2.4.6-shell 11
``` 
  
# 2 内核参数

```
* soft nproc 60000
* hard nproc 60000
* soft nofile 4194304
* hard nofile 4194304
```
# 3 Pam
## 3.1  pam_succeed allow user1  to "su - user2"
>需求描述
>机器有N个用户，不同用户隶属不通goup，group-user有权限做一些事情所以需要，组内用户>可以免密码su到group-user，并且用户不配置密码
>http://www.361way.com/pam-limit-user-login/4269.html
>https://dzone.com/articles/linux-pam-easy-guide

```
p-user  p-group
user1   group1 p-group
user2   group2 p-group
配置文件/etc/pam.d/su
#配置一：user1/2 可以"su - p-user", user1 属于组group1 和 p-group
#打开这行注释
auth            sufficient      pam_rootok.so
auth       [success=ignore default=1] pam_succeed_if.so user = p-user
auth       sufficient   pam_succeed_if.so use_uid user ingroup p-group


p-user  p-group
user1   group1
#配置二： user1 可以免密码 "su - p-user"
auth            sufficient      pam_rootok.so
auth       [success=ignore default=1] pam_succeed_if.so user = p-user
auth       sufficient   pam_succeed_if.so use_uid user = user1



例子二：
#需求描述，同一台机器两组用户group1和group2， group1的用户可以su group1组，group2的用户可以su group2，配置如下:

auth		sufficient	pam_rootok.so
auth       [success=ignore default=2] pam_succeed_if.so user = xxx
auth       [success=ignore default=1]   pam_succeed_if.so  use_uid user ingroup $group1
auth       [success=done default=ignore]  pam_permit.so
auth       [success=ignore default=2]     pam_succeed_if.so user = xxx
auth       [success=ignore default=1]     pam_succeed_if.so use_uid user ingroup $group2
auth       [success=done default=ignore]  pam_permit.so
```
## 3.2  pam_wheel
>描述：
>有些时候需要系统中的部分用户可以su root，及时有些用户su root后密码输入正确，也不让他su成功，就需要以下配置

```
一：
vim /etc/pam.d/su
#打开注释
auth           required        pam_wheel.so use_uid

二：
修改/etc/login.defs文件,可以新建一个用户，再su登陆发现无法正常su过去，通过如下的命令将用户加入到wheel组后，其可以正常su登陆。

echo "SU_WHEEL_ONLY yes" >> /etc/login.defs

三:
usermod -G wheel 用户名

四：
vim /etc/pam.d/su
auth required /lib/security/pam_wheel.so group=test
```
# 4 Git
## 4.1 git 配置部署的秘钥对

```
ssh-keygen -f test   -C "test"
cat .ssh/config
Host xxx.com
  HostName xx.com
  Port 22x
  User git
  IdentityFile ~/.ssh/test
```
# 5 centos内核参数

## 5.1  ulimit

```
/etc/security/limits.d/90-nofile.conf
*       soft    nofile     3922960
*       hard    nofile     3922960

sysctl -p   # 立即生效

$ ulimit -a
-t: cpu time (seconds)              unlimited
-f: file size (blocks)              unlimited
-d: data seg size (kbytes)          unlimited
-s: stack size (kbytes)             8192
-c: core file size (blocks)         0
-m: resident set size (kbytes)      unlimited
-u: processes                       7854
-n: file descriptors                1024
-l: locked-in-memory size (kbytes)  64
-v: address space (kbytes)          unlimited
-x: file locks                      unlimited
-i: pending signals                 7854
-q: bytes in POSIX msg queues       819200
-e: max nice                        0
-r: max rt priority                 0
-N 15:                              unlimited

ulimit 常用参数：

ulimit -a：查看当前 shell 的所有资源限制，默认显示软限制
ulimit -Sa：查看当前 shell 的所有资源限制，-S 表示显示软限制
ulimit -Ha：查看当前 shell 的所有资源限制，-H 表示显示硬限制
ulimit -n：显示当前可打开的文件描述符数量，软限制
ulimit -Hn：显示当前可打开的文件描述符数量，硬限制
ulimit -Sn 65536：修改可打开的文件描述符数为 65536，软限制
ulimit -Hn 65536：修改可打开的文件描述符数为 65536，硬限制
ulimit -HSn 65536：修改可打开的文件描述符数为 65536，软限制 + 硬限制
ulimit -n 65536：修改可打开的文件描述符数为 65536，软限制 + 硬限制（sh/bash）
```

## 5.2 内核参数优化

```
#编辑 /etc/sysctl.conf 或 /etc/sysctl.d/*.conf
vm.overcommit_memory = 1
fs.nr_open = 10000000
fs.file-max = 500000000
net.ipv4.ip_forward = 1
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 0
net.ipv4.tcp_fin_timeout = 15
net.ipv4.ip_local_port_range = 10000 65535
net.ipv4.tcp_max_tw_buckets = 5000
net.ipv4.tcp_max_syn_backlog = 10240
net.core.netdev_max_backlog = 10240
net.core.somaxconn = 10240
net.ipv4.tcp_retries1 = 1
net.ipv4.tcp_retries2 = 3
net.ipv4.tcp_syn_retries = 2
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_keepalive_time = 30
net.ipv4.tcp_keepalive_intvl = 2
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_max_orphans = 10240
net.core.rmem_default = 1048576
net.core.wmem_default = 1048576
net.core.rmem_max = 12582912
net.core.wmem_max = 12582912
net.core.optmem_max = 12582912
net.ipv4.tcp_rmem = 16384 1048576 12582912
net.ipv4.tcp_wmem = 16384 1048576 12582912
net.ipv4.tcp_fastopen = 3
net.ipv4.tcp_no_metrics_save = 0
net.ipv4.tcp_slow_start_after_idle = 0
net.core.default_qdisc = fq
net.ipv4.tcp_congestion_control = bbr

# 内核参数解释
vm.overcommit_memory = 1                    # 允许内核分配所有可用的物理内存
fs.nr_open = 10000000                       # 单个进程允许的最大 fd 数量
fs.file-max = 500000000                     # linux 内核允许的最大 fd 数量
net.ipv4.ip_forward = 1                     # 允许网卡之间的数据包转发
net.ipv4.tcp_syncookies = 1                 # 启用syncookies, 可防范少量syn攻击
net.ipv4.tcp_tw_reuse = 0                   # 重用time_wait的tcp端口(建议禁用)
net.ipv4.tcp_fin_timeout = 15               # fin_wait_2超时时间
net.ipv4.ip_local_port_range = 10000 65535  # 动态分配端口的范围
net.ipv4.tcp_max_tw_buckets = 5000          # time_wait套接字最大数量
net.ipv4.tcp_max_syn_backlog = 10240        # syn队列长度
net.core.netdev_max_backlog = 10240         # 最大设备队列长度
net.core.somaxconn = 10240                  # listen()的默认参数, 等待请求的最大数量
net.ipv4.tcp_retries1 = 1                   # tcp 连接丢包重传次数，达到此值将刷新路由缓存
net.ipv4.tcp_retries2 = 3                   # tcp 连接丢包重传次数，达到此值将断开 TCP 连接
net.ipv4.tcp_syn_retries = 2                # 放弃建立连接前内核发送syn包的数量
net.ipv4.tcp_synack_retries = 2             # 放弃连接前内核发送syn+ack包的数量
net.ipv4.tcp_keepalive_time = 30            # keepalive idle空闲时间
net.ipv4.tcp_keepalive_intvl = 2            # keepalive intvl间隔时间
net.ipv4.tcp_keepalive_probes = 3           # keepalive probes最大探测次数
net.ipv4.tcp_max_orphans = 10240            # 内核允许的最大孤立socket数量
net.core.rmem_default = 1048576             # socket默认读buffer大小
net.core.wmem_default = 1048576             # socket默认写buffer大小
net.core.rmem_max = 12582912                # socket最大读buffer大小
net.core.wmem_max = 12582912                # socket最大写buffer大小
net.core.optmem_max = 12582912              # socket最大内存buffer大小
net.ipv4.tcp_rmem = 16384 1048576 12582912  # tcp_socket读buffer大小. min/default/max
net.ipv4.tcp_wmem = 16384 1048576 12582912  # tcp_socket写buffer大小. min/default/max
net.ipv4.tcp_fastopen = 3                   # 开启tcp_fastopen（内核 3.7 +）
net.ipv4.tcp_no_metrics_save = 0            # 在路由中缓存 TCP 连接的各项指标
net.ipv4.tcp_slow_start_after_idle = 0      # 在连接空闲期间保持拥塞窗口的大小
net.core.default_qdisc = fq                 # 启用 BBR 拥塞控制算法（需内核支持）
net.ipv4.tcp_congestion_control = bbr       # 启用 BBR 拥塞控制算法（需内核支持）
#禁用 IPv6
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
```
# 6 yum pip
## 6.1 yum
```
## 安装 gcc/g++ 编译环境
yum -y groupinstall "Development Tools"

## 安装 epel 源
yum -y install epel-release

## 安装常用工具
yum -y install vim curl wget unzip p7zip ipset bind-utils telnet nc nmap openssh openssl zsh git tcpdump iproute psmisc mlocate ctags mailx bc xorg-x11-xauth xorg-x11-server-utils xterm

## 安装常用依赖
yum -y install curl-devel pcre-devel readline-devel sqlite-devel openssl-devel

## yum 常用插件
yum -y install yum-plugin-fastestmirror

## yum 常用参数
yum check-update    # 检查软件是否有更新
yum update -y       # 更新所有 rpm 包

yum provides xhost  # 查询哪个 rpm 包提供了 xhost 命令
yum search telnet   # 以名称查找 rpm 包

yum deplist nginx   # 查看 nginx 包依赖

yum clean dbcache
yum clean headers
yum clean metadata
yum clean packages
yum clean all       # 清除 dbcache headers packages metadata

## 重建 yum 缓存
yum clean all
yum makecache
yum makecache fast  # 建立 fast_mirrors 缓存

## 查询 ipset 命令属于哪个 rpm 包
rpm -qf `which ipset`
```

- epel


```
官网 --> http://mirrors.ustc.edu.cn/fedora/epel/

CentOS 6
rpm -ivh http://mirrors.ustc.edu.cn/fedora/epel/epel-release-latest-6.noarch.rpm

CentOS 7
rpm -ivh http://mirrors.ustc.edu.cn/fedora/epel/epel-release-latest-7.noarch.rpm
```
## 6.2 pip

```
pip国内的一些镜像
阿里云 http://mirrors.aliyun.com/pypi/simple/
中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/
豆瓣(douban) http://pypi.douban.com/simple/
清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/
中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/

pip install trash-cli -i https://pypi.tuna.tsinghua.edu.cn/simple
```
# 7 ssh配置
## 7.1 ssh_config
```
## 监听地址
AddressFamily any       # any|inet|inet6
ListenAddress 0.0.0.0   # ipv4 0/0
ListenAddress ::        # ipv6 0/0
Port 1234               # 监听端口(不要使用默认端口)
Protocol 2              # 使用SSH2
PidFile /run/sshd.pid   # pid 文件

## HostKey
HostKey /etc/ssh/ssh_host_rsa_key

## 日志相关
LogLevel INFO           # 日志级别INFO
SyslogFacility AUTH     # 记录认证信息

## 安全相关
LoginGraceTime 30                   # 限定用户必须在指定时间内认证成功，默认 120 秒
PermitRootLogin without-password    # 是否允许 root 用户登录 yes|no|without-password
StrictModes yes                     # 是否对用户主目录及配置文件进行宿主和权限检查
MaxAuthTries 3                      # 限定每个连接最大允许的认证重试次数
MaxSessions 15                      # 限定每个 IP 的最大 SSH 会话数
AllowUsers root                     # 只允许指定用户登录，使用空格隔开

## 认证相关
UsePam yes                                  # 启用PAM认证
PubkeyAuthentication yes                    # 允许公钥认证
AuthorizedKeysFile  .ssh/authorized_keys    # 公钥文件路径(家目录)
PasswordAuthentication no                   # 允许密码认证，不推荐
PermitEmptyPasswords no                     # 允许空密码认证，不推荐
IgnoreUserKnownHosts yes                    # 忽略 ~/.ssh/known_hosts 文件
IgnoreRhosts yes                            # 忽略 ~/.rhosts、~/.shosts 文件

## X11 相关
X11Forwarding yes       # 是否允许 X11 转发
X11UseLocalhost yes     # 是否绑定到loopback地址
X11DisplayOffset 10     # DISPLAY环境变量的偏移量

## KeepAlive
TCPKeepAlive no
ClientAliveCountMax 3
ClientAliveInterval 15

## 其它配置
PrintMotd no        # 打印欢迎信息
PrintLastLog yes    # 打印上次登录日志
UseDNS no           # 是否进行DNS反向解析
Subsystem   sftp    /usr/lib/ssh/sftp-server    # 注意修改为实际 sftp-server 路径

# 忽略 known_hosts 
## 不检测 known_hosts
StrictHostKeyChecking no
## 不保存 known_hosts
UserKnownHostsFile /dev/null
## 设置日志等级为 quiet
LogLevel QUIET

# TCP KeepAlive
## 关闭 tcp keepalive 功能
TCPKeepAlive no
## 如果服务器连续 3 次未回应则关闭连接
ServerAliveCountMax 3
## 客户端每 15s 向服务器发送一个心跳包
ServerAliveInterval 15
```
## 7.2 ssh代理


```
ssh 使用 socks5、http_connect 代理：
ssh -oProxyCommand="nc -X5 -x127.0.0.1:1080 %h %p" USER@SSH_SERVER，通过 socks5 代理
ssh -oProxyCommand="nc -Xconnect -x127.0.0.1:1080 %h %p" USER@SSH_SERVER，通过 http_connect 代理

scp/sftp 使用 socks5、http_connect 代理：
scp -Cpr -oProxyCommand="nc -X5 -x127.0.0.1:1080 %h %p" files USER@SSH_SERVER:/tmp/
scp -Cpr -oProxyCommand="nc -Xconnect -x127.0.0.1:1080 %h %p" files USER@SSH_SERVER:/tmp/
sftp -oProxyCommand="nc -X5 -x127.0.0.1:1080 %h %p" USER@SSH_SERVER
sftp -oProxyCommand="nc -Xconnect -x127.0.0.1:1080 %h %p" USER@SSH_SERVER

MAC ssh config:
 cat .ssh/config
 ProxyCommand /usr/local/bin/ncat -i 2147483ms --proxy proxy.xxx.com:8080 --proxy-type http %h %p
 ServerAliveInterval 30 #每隔30秒发一次心跳，防止ssh自动断开
```
## 7.3 ssh端口转发

```
#本地端口转发
ssh -L [listen_ip:]listen_port:target_ip:target_port user@ssh_server
# -L 选项：本地端口转发
# listen_ip：本地监听地址，默认为127.0.0.1和[::1]
# listen_port：本地监听端口
# target_ip：目的主机地址，即要转发给谁
# target_port：目的主机端口

# 通常我们使用端口转发时，是不需要登录远程主机的，因此可以使用 -CNf 选项
# -C 选项：启用压缩，节省带宽资源
# -N 选项：不登陆shell，即不会打开 shell 进程
# -f 选项：后台运行，即守护进程模式

# 命令举例：
ssh -CNf -L 192.168.1.101:80:ip.cn:80 root@zfl9.com
ssh -CNf -L 80:ip.cn:80 root@zfl9.com        # 监听127.0.0.1 [::1]
ssh -CNf -L :80:ip.cn:80 root@zfl9.com       # 监听0.0.0.0 [::]
ssh -CNf -L *:80:ip.cn:80 root@zfl9.com      # 同上
ssh -CNf -L 0.0.0.0:ip.cn:80 root@zfl9.com   # 监听0.0.0.0
ssh -CNf -L \[::\]:80:ip.cn:80 root@zfl9.com # 监听[::]

# 应用举例：
ssh -CNf -L 8080:ip.cn:80 root@zfl9.com
# 执行完毕后，ssh会在本地监听 127.0.0.1:8080 地址
# 任何发往 127.0.0.1:8080 的数据包都会通过 ssh 隧道被 ssh_server 转发给 ip.cn:80
# 当 ip.cn:80 响应后，ssh_server 会将响应数据包通过 ssh 隧道转发给本地主机
# 因此下面的命令会打印出 ssh 服务器的 IP 地址信息
curl -x 127.0.0.1:8080 ip.cn

#远程端口转发
ssh -R server_listen_port:target_ip:target_port user@ssh_server
# -R 选项：远程端口转发
# server_listen_port：ssh_server 监听端口，这里不能指定监听地址，默认是 127.0.0.1 和 [::1]
# target_ip：目的主机地址，一般这个地址是当前主机可访问的
# target_port：目的主机端口

# 应用举例：
ssh -CNf -R 8080:ip.cn:80 root@zfl9.com
# 执行完毕后，ssh_server 会在服务器上监听 127.0.0.1:8080 地址
# 任何发往 ssh_server 127.0.0.1:8080 的数据包都会通过 ssh 隧道被本地主机转发给 ip.cn:80
# 当 ip.cn:80 响应后，本地主机会将响应数据包通过 ssh 隧道转发给 ssh_server 主机
# 可以看出，远程端口转发和本地端口转发是一个相反的流程。
# 所以，在 ssh_server 上执行下面的命令会打印出本地主机的 IP 地址信息
curl -x 127.0.0.1:8080 ip.cn

# 最典型的应用 - 穿透 NAT
# 比如我在自己家里搭建了一台内网 http 服务器，
# 平时我都是在内网环境中进行访问的，完全没问题。
# 但是，我现在想在公网环境下访问我的内网 http 服务器，该怎么做？
# 因为在内网环境中上网都是要经过路由器网关的，均做了 NAT 转换。
# 出去容易，但是进来就比较难了，被路由器挡住了。
# 这时就可以利用远程端口转发进行NAT穿透：
# 首先在本地主机执行 ssh 命令，假设内网 http 服务器地址为 192.168.1.100:80
ssh -CNf -R 8080:192.168.1.100:80 root@zfl9.com
# 然后登录 ssh_server 服务器，执行以下命令就可以访问网页了
curl -x 127.0.0.1:8080 192.168.1.100

#动态端口转发
ssh -D listen_ip:listen_port user@ssh_server
# -D 选项：动态端口转发，其实应该说是 socks5 代理
# listen_ip：监听地址
# listen_port：监听端口

# 应用举例：
ssh -CNf -D 0.0.0.0:9999 root@zfl9.com
# 执行完毕后，ssh 会监听地址 0.0.0.0:9999，该地址提供 socks5 代理
# socks 协议估计大家都比较熟悉，最大的用途就是 FQ 科学上网了
# 这时候只要在 Chrome/Firefox 上配置 socks5 代理就可以畅游互联网了！
# 不过前提是你的服务器不在大陆，比如可以是香港的、日本的，速度都比较快！
```
# Q&&A
## 1 mac升级后编码错误

```
【问题描述】
-bash: 警告:setlocale: LC_CTYPE: 无法改变区域选项 (UTF-8): 没有那个文件或目录

【解决方案】
sudo vim /etc/ssh/ssh_config
注释掉   SendEnv LANG LC_*
```
## 2 ssh 登录失败


```
#错误信息
  unix_chkpwd[7485]: could not obtain user info ()
  sshd[7483]: fatal: Access denied for user   by PAM account configuration [preauth]
  #解决方法
 vim  /etc/pam.d/sshd
 
 #这行后面添加-auth      optional     pam_reauthorize.so prepare 
 account    sufficient   pam_localuser.so
```